{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fb9feba",
   "metadata": {},
   "source": [
    "# Width and Basin Attributte Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9aec61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import ee\n",
    "#ee.Authenticate()\n",
    "ee.Initialize() #opt_url='https://earthengine-highvolume.googleapis.com'\n",
    "import geemap\n",
    "import geemap.foliumap as geemap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f948cd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Useful functions\n",
    "\n",
    "#Add long and lat as feature properties\n",
    "def longLat (feat):\n",
    "    geom = feat.geometry()\n",
    "    long = geom.coordinates().get(0)\n",
    "    lat = geom.coordinates().get(-1)\n",
    "    return feat.set('long', long, 'lat', lat)\n",
    "\n",
    "def polyProps(polygon):\n",
    "    pfaf = polygon.get('PFAF_ID')\n",
    "    sort = polygon.get('SORT')\n",
    "    hybas = polygon.get('HYBAS_ID')\n",
    "    basinArea = polygon.get('SUB_AREA')\n",
    "    upArea =  polygon.get('UP_AREA')\n",
    "    distMain =  polygon.get('DIST_MAIN')\n",
    "    points = ee.FeatureCollection(ee.List(polygon.get('points'))).map(lambda point : point.set({'SORT': sort,\n",
    "                                                                                               'DIST_MAIN': distMain}))\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1f8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3bde69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at basins of interest or your sites too\n",
    "\n",
    "Map = geemap.Map(center=(40, -100), zoom=4)\n",
    "\n",
    "level = '06'\n",
    "dataset =  ee.FeatureCollection(\"WWF/HydroATLAS/v1/Basins/level\" + level) \n",
    "\n",
    "visualization = {\n",
    "  'color' : '808080',\n",
    "  'strokeWidth':1\n",
    "}\n",
    "\n",
    "Map.addLayer(sites, {'color': 'purple'}, 'My sites')\n",
    "\n",
    "\n",
    "Map.setCenter(-92.140225737902,37.08486741, 7);\n",
    "Map.addLayer(dataset, visualization, 'Basins');\n",
    "Map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad839358",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Draw in sites\n",
    "sites = ee.FeatureCollection('your_filepath')\n",
    "#Define your sites\n",
    "table = sites\n",
    "print(table.size().getInfo())\n",
    "\n",
    "#Filter geometry and props for basin\n",
    "feats = dataset.select(['SORT', 'PFAF_ID', 'HYBAS_ID', 'SUB_AREA', 'UP_AREA', 'DIST_MAIN']).filterBounds(table.geometry().bounds())\n",
    "\n",
    "\n",
    "spatialFilter = ee.Filter.intersects(**{\n",
    "  'leftField': '.geo',\n",
    "  'rightField': '.geo',\n",
    "  'maxError': 10\n",
    "})\n",
    "\n",
    "saveAllJoin = ee.Join.saveAll(**{\n",
    "  'matchesKey': 'points'\n",
    "})\n",
    "\n",
    "intersectJoined = saveAllJoin.apply(**{\n",
    "    'primary': feats, \n",
    "    'secondary': table, \n",
    "    'condition': spatialFilter\n",
    "  }).map(polyProps).flatten()\n",
    "\n",
    "intersectJoined = intersectJoined.map(lambda feat : feat.set('long', feat.geometry().coordinates().get(0), 'lat', feat.geometry().coordinates().get(-1)))\n",
    "\n",
    "print(intersectJoined.size().getInfo())  \n",
    "print(intersectJoined.limit(10).getInfo(), 'intersectJoined')\n",
    "\n",
    "##Save\n",
    "# filepath = '/your_filepath/basinAttributes'+ level+ '_sites.csv'\n",
    "# geemap.ee_export_vector(ee.FeatureCollection(intersectJoined), filepath)\n",
    "\n",
    "##OR \n",
    "##Export an ee.FeatureCollection as an Earth Engine asset.\n",
    "# task = ee.batch.Export.table.toAsset(\n",
    "#     collection = intersectJoined, \n",
    "#     description = 'basinAttributesExport', \n",
    "#     assetId = 'yourSiteFileName'\n",
    "# )\n",
    "# task.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39344bcd",
   "metadata": {},
   "source": [
    "# Widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560e0303",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assumes you've loaded your site list+location as gee asset called 'sites'\n",
    "\n",
    "#add lat long as property and sort by one or the other (computationally more efficient for width below code)\n",
    "sites = sites.map(longLat).sort('lat')\n",
    "print(sites.limit(2).getInfo())\n",
    "\n",
    "#GRWL widths\n",
    "grwl_water_vector = ee.FeatureCollection(\"projects/sat-io/open-datasets/GRWL/water_vector_v01_01\") #more exact\n",
    "grwl_summary = ee.FeatureCollection(\"projects/sat-io/open-datasets/GRWL/grwl_SummaryStats_v01_01\") #computationally cheap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb63a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FC as list\n",
    "sitesList = sites.toList(8000) #sort by lat or long for\n",
    "\n",
    "# Chunk size, define for computational feasibility\n",
    "chunk_size = 5\n",
    "\n",
    "# List to store chunks\n",
    "chunks = []\n",
    "\n",
    "# Split the list into chunks\n",
    "for i in range(0, len(ee.List(sitesList).getInfo()), chunk_size):\n",
    "    chunk = sitesList.slice(i,i + chunk_size)\n",
    "    chunks.append(chunk)\n",
    "\n",
    "print(len(chunks))\n",
    "#print((chunks[121]).getInfo())\n",
    "#print(ee.FeatureCollection(chunks[3]).getInfo())\n",
    "\n",
    "\n",
    "### maybe you need a special subset that did not work the first time?\n",
    "# special = ee.FeatureCollection(chunks[1])\n",
    "# special1 = ee.FeatureCollection(chunks[1]).toList(50).slice(0,15)\n",
    "# special2 = ee.FeatureCollection(chunks[1]).toList(50).slice(15,30)\n",
    "\n",
    "# specials = [special1, special2]\n",
    "# print(specials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba413d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first few chunks\n",
    "for i, chunk in enumerate(chunks):\n",
    "    \n",
    "    chunk = ee.FeatureCollection(chunk)\n",
    "    \n",
    "    #Get the GRWL summary vector and trim to area and feature of interest, add buffer if sites are on shore\n",
    "    grwl_summary_intersect = grwl_water_vector \\\n",
    "      .select('width_m') \\\n",
    "      .filterBounds(chunk.geometry().bounds())\\\n",
    "      .map(lambda feat: feat.buffer(ee.Number(0.8).multiply((feat.get('width_m'))), 10))\n",
    "\n",
    "\n",
    "    #Define an geometry intersection\n",
    "    interesectsFilter = ee.Filter.intersects(**{\n",
    "      'leftField': '.geo',\n",
    "      'rightField': '.geo',\n",
    "      'maxError': 50\n",
    "    })\n",
    "\n",
    "    #Join the two datasets\n",
    "    siteWidths = ee.Join.saveFirst('widths').apply(**{\n",
    "       'primary': chunk,\n",
    "      'secondary': grwl_summary_intersect.filterBounds(chunk.geometry().bounds()),\n",
    "      'condition': interesectsFilter\n",
    "    }).filter(ee.Filter.neq('widths', None))\n",
    "\n",
    "\n",
    "    widthExtract = ee.FeatureCollection(hucWidths.aggregate_array('widths').flatten())\n",
    "\n",
    "\n",
    "    # Load the first feature collection.\n",
    "    fc1 = siteWidths\n",
    "\n",
    "    # Load the second feature collection.\n",
    "    fc2 = widthExtract\n",
    "\n",
    "    # Map over the features in both collections and combine properties.\n",
    "\n",
    "    def widthCombine(feature1):\n",
    "      # Get the properties of the first feature.\n",
    "        properties1 = feature1.toDictionary()\n",
    "      # Find the corresponding feature in the second collection.\n",
    "        feature2 = fc2.filterBounds(feature1.geometry()).first()\n",
    "      # Assuming geometry is the basis for association\n",
    "      # Get the properties of the second feature.\n",
    "        properties2 = feature2.toDictionary()\n",
    "      # Combine the properties from both features.\n",
    "        combinedProperties = properties1.combine(properties2)\n",
    "\n",
    "      # Create a new feature with the combined properties.\n",
    "        return ee.Feature(feature1.geometry(), combinedProperties)\n",
    "    \n",
    "    \n",
    "    try: \n",
    "        combinedFeatures = fc1.map(widthCombine) #\\\n",
    "          #.filter(ee.Filter.gte('width_mean', 90))\n",
    "\n",
    "        def latLong(feat):\n",
    "            geom = feat.geometry()\n",
    "            long = geom.coordinates().get(0)\n",
    "            lat = geom.coordinates().get(-1)\n",
    "            return feat.set('long', long, 'lat', lat).setGeometry(None)\n",
    "\n",
    "        combinedFeatures = combinedFeatures.map(latLong)\n",
    "\n",
    "\n",
    "        filepath = 'your_filepath/'+ str(i) + '_someOtherIdentifierMaybe'+'.csv'\n",
    "        geemap.ee_export_vector(ee.FeatureCollection(combinedFeatures), filepath, ['SiteID', 'width_m', 'lat','long'])\n",
    "\n",
    "    except Exception as error:\n",
    "        print(\"An error occurred,\", error)\n",
    "        pass\n",
    "\n",
    "#     task = ee.batch.Export.table.toDrive(\n",
    "#                         collection = ee.FeatureCollection(combinedFeatures), \n",
    "#                         description = str(i + 138) + '_' + 'aquaWidths', \n",
    "#                         folder = 'aquaWidths', \n",
    "#                         fileFormat = 'csv',\n",
    "#                         selectors = ['SiteID','SiteID2', 'width_mean', 'lat', 'long'])\n",
    "\n",
    "\n",
    "\n",
    "    #Start the task\n",
    "    #task.start()\n",
    "    #while task.active():\n",
    "        #print('Polling for task (id: {}).'.format(task.id), i)\n",
    "        #time.sleep(5)\n",
    "    \n",
    "    print('done', i)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab969ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stitch together when done, filter, and hydrobasin\n",
    "file_list = glob.glob('/width_files/*.csv')\n",
    "widths = pd.concat(list(map(lambda file: pd.read_csv(file, low_memory=False), file_list)), ignore_index=True)\n",
    "print(widths.shape[0])\n",
    "print(widths.head())\n",
    "\n",
    "widths = widths[widths['width_m'] >= 90]\n",
    "print(widths.shape[0])\n",
    "print(widths.head())\n",
    "\n",
    "#SAVE\n",
    "widths.to_csv('/your_filepath.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee",
   "language": "python",
   "name": "gee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
